#!/usr/bin/env python3
"""
æ”¹å–„ã•ã‚ŒãŸéŸ³éŸ»çš„é¡ä¼¼åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
ç‰¹ã«é•·æ–‡å¯¾å¿œã®æ¤œè¨¼ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹
"""

import sys
import os

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_improved_verification():
    """æ”¹å–„ã•ã‚ŒãŸéŸ³éŸ»çš„æ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""
    try:
        from phonetic_similarity import EnhancedWakeWordVerifier
        
        print("ğŸ” æ”¹å–„ã•ã‚ŒãŸéŸ³éŸ»çš„é¡ä¼¼åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ")
        print("=" * 60)
        
        verifier = EnhancedWakeWordVerifier("ãƒ«ã‚¯ã‚¹")
        
        # å®Ÿéš›ã®ãƒ­ã‚°ã‹ã‚‰å–å¾—ã—ãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = [
            # (å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ, æœŸå¾…çµæœ, èª¬æ˜)
            ("ã‚‹ãã™", True, "ã²ã‚‰ãŒãªåŸºæœ¬å½¢"),
            ("ãƒ«ãƒƒã‚¯ã‚¹", True, "ä¿ƒéŸ³æŒ¿å…¥"),
            ("ãƒ«ãƒ¼ã‚¯ã‚¹", True, "é•·éŸ³å¤‰åŒ–"), 
            ("ãƒ«ã‚¯ã‚¹ é›»æ°—ã‚’ã¤ã‘ã¦", True, "ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰+ã‚³ãƒãƒ³ãƒ‰ï¼ˆé‡è¦ï¼‰"),
            ("ãƒ«ãƒ¼ã‚¯ã‚¹é›»æ°—ã‚’ã¤ã‘ã¦", True, "ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰+ã‚³ãƒãƒ³ãƒ‰ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ãªã—ï¼‰"),
            ("ä»Šæ—¥ã¯ãƒ«ã‚¯ã‚¹", True, "å‰ç½®è©ä»˜ãã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰"),
            ("é›»æ°—ã‚’ã¤ã‘ã¦ãƒ«ã‚¯ã‚¹", True, "å¾Œç½®ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰"),
            ("ãƒ«ã‚¯ã‚¹ã€ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ", True, "å¥èª­ç‚¹ä»˜ãã‚³ãƒãƒ³ãƒ‰"),
            ("ã“ã‚“ã«ã¡ã¯ãƒ«ã‚¯ã‚¹ã€é›»æ°—ã‚’æ¶ˆã—ã¦", True, "è¤‡é›‘ãªæ–‡ç« "),
            ("looks", False, "è‹±èªã®é¡ä¼¼èª"),
            ("ãƒ–ãƒƒã‚¯ã‚¹", False, "éé–¢é€£èª"),
            ("", False, "ç©ºæ–‡å­—åˆ—"),
        ]
        
        print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ (æ”¹å–„ç‰ˆ):")
        print("-" * 60)
        
        success_count = 0
        total_count = len(test_cases)
        
        for i, (text, expected, description) in enumerate(test_cases, 1):
            context = {
                'text_length': len(text),
                'noise_level': 0.3,
                'recognition_confidence': 0.9
            }
            
            is_verified, confidence, details = verifier.verify_wake_word(text, context)
            
            # çµæœåˆ¤å®š
            is_success = (is_verified == expected)
            result_mark = "âœ…" if is_success else "âŒ"
            
            if is_success:
                success_count += 1
            
            print(f"{result_mark} {i:2d}. {description}")
            print(f"     å…¥åŠ›: '{text}'")
            print(f"     çµæœ: {is_verified} (æœŸå¾…å€¤: {expected})")
            print(f"     ä¿¡é ¼åº¦: {confidence:.3f} (é–¾å€¤: {details.get('threshold_used', 0.7):.3f})")
            print(f"     å‡¦ç†æ™‚é–“: {details.get('processing_time_ms', 0):.1f}ms")
            
            if details.get('extracted_part'):
                print(f"     æŠ½å‡ºéƒ¨åˆ†: '{details['extracted_part']}'")
            
            if details.get('context_adjustment', 0) != 0:
                print(f"     é–¾å€¤èª¿æ•´: {details['context_adjustment']:+.3f}")
            
            print()
        
        # çµæœã‚µãƒãƒªãƒ¼
        success_rate = success_count / total_count * 100
        print("=" * 60)
        print(f"ğŸ“ˆ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"   æˆåŠŸ: {success_count}/{total_count} ({success_rate:.1f}%)")
        
        # çµ±è¨ˆæƒ…å ±
        stats = verifier.get_verification_statistics()
        print(f"   ç·æ¤œè¨¼å›æ•°: {stats['total_verifications']}")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {stats['average_processing_time']:.2f}ms")
        
        if success_rate >= 90:
            print("ğŸ‰ å„ªç§€ãªçµæœã§ã™ï¼")
        elif success_rate >= 75:
            print("âœ… è‰¯å¥½ãªçµæœã§ã™ã€‚")
        else:
            print("âš ï¸ æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        
        return success_rate >= 75
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_long_text_extraction():
    """é•·æ–‡ã‹ã‚‰ã®ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
    try:
        from phonetic_similarity import PhoneticSimilarityCalculator
        
        print("\nğŸ” é•·æ–‡æŠ½å‡ºæ©Ÿèƒ½ã®è©³ç´°ãƒ†ã‚¹ãƒˆ")
        print("=" * 50)
        
        calculator = PhoneticSimilarityCalculator()
        
        test_texts = [
            "ãƒ«ã‚¯ã‚¹ é›»æ°—ã‚’ã¤ã‘ã¦",
            "ä»Šæ—¥ã¯ãƒ«ã‚¯ã‚¹ãŠç–²ã‚Œæ§˜",
            "é›»æ°—ã‚’æ¶ˆã—ã¦ãƒ«ã‚¯ã‚¹",
            "ãƒ«ãƒ¼ã‚¯ã‚¹ä»Šæ—¥ã®å¤©æ°—æ•™ãˆã¦",
            "ã“ã‚“ã«ã¡ã¯ãƒ«ãƒƒã‚¯ã‚¹ã€éŸ³æ¥½ã‚’ã‹ã‘ã¦",
        ]
        
        for text in test_texts:
            similarity, extracted = calculator.extract_wake_word_from_long_text(text, "ãƒ«ã‚¯ã‚¹")
            print(f"å…¥åŠ›: '{text}'")
            print(f"æŠ½å‡º: '{extracted}' (é¡ä¼¼åº¦: {similarity:.3f})")
            print()
        
        return True
        
    except Exception as e:
        print(f"âŒ é•·æ–‡æŠ½å‡ºãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ æ”¹å–„ã•ã‚ŒãŸéŸ³éŸ»çš„é¡ä¼¼åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  - æ¤œè¨¼ãƒ†ã‚¹ãƒˆ")
    print("ç‰¹ã«é•·æ–‡ãƒ»è¤‡åˆæ–‡ã®å‡¦ç†èƒ½åŠ›ã‚’é‡ç‚¹çš„ã«ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    basic_test_ok = test_improved_verification()
    extraction_test_ok = test_long_text_extraction()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ æœ€çµ‚ãƒ†ã‚¹ãƒˆçµæœ:")
    print(f"åŸºæœ¬æ¤œè¨¼ãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if basic_test_ok else 'âŒ å¤±æ•—'}")
    print(f"é•·æ–‡æŠ½å‡ºãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if extraction_test_ok else 'âŒ å¤±æ•—'}")
    
    if basic_test_ok and extraction_test_ok:
        print("\nğŸ‰ æ”¹å–„ãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("é•·æ–‡å¯¾å¿œæ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        print("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
