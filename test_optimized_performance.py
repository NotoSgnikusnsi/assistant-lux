#!/usr/bin/env python3
"""
æœ€é©åŒ–ã•ã‚ŒãŸéŸ³éŸ»çš„æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import time

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_performance_optimization():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ éŸ³éŸ»çš„é¡ä¼¼åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    
    try:
        from phonetic_similarity import EnhancedWakeWordVerifier
        
        verifier = EnhancedWakeWordVerifier("ãƒ«ã‚¯ã‚¹")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = [
            # (å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ, èª¬æ˜, æœŸå¾…ã•ã‚Œã‚‹å‡¦ç†æ™‚é–“(ms))
            ("ãƒ«ã‚¯ã‚¹", "çŸ­æ–‡ãƒ»å®Œå…¨ä¸€è‡´", 1.0),
            ("ã‚‹ãã™", "çŸ­æ–‡ãƒ»ã²ã‚‰ãŒãª", 1.0),
            ("ãƒ©ã‚¯ã‚¹", "çŸ­æ–‡ãƒ»éŸ³éŸ»å¤‰åŒ–", 1.0),
            ("ãƒ«ã‚¯ã‚¹ ä»Šæ—¥ã®å¤©æ°—ã‚’æ•™ãˆã¦", "é•·æ–‡ãƒ»ã‚³ãƒãƒ³ãƒ‰ä»˜ã", 3.0),
            ("ä»Šæ—¥ã¯ãƒ«ã‚¯ã‚¹ã€é›»æ°—ã‚’ã¤ã‘ã¦", "é•·æ–‡ãƒ»å‰ç½®è©ä»˜ã", 3.0),
            ("ãŠã¯ã‚ˆã†ã€ãƒ«ã‚¯ã‚¹ã•ã‚“ã€ä»Šæ—¥ã¯ã©ã‚“ãªä¸€æ—¥ã«ãªã‚‹ã§ã—ã‚‡ã†ã‹ï¼Ÿ", "éå¸¸ã«é•·ã„æ–‡", 5.0),
            ("ã“ã‚“ã«ã¡ã¯", "çŸ­æ–‡ãƒ»ç„¡é–¢ä¿‚èª", 1.0),
            ("ãƒ–ãƒƒã‚¯ã‚¹", "çŸ­æ–‡ãƒ»é¡ä¼¼èª", 1.0),
        ]
        
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœ:")
        print("-" * 70)
        
        total_time = 0
        fast_count = 0
        
        for i, (text, description, expected_time) in enumerate(test_cases, 1):
            context = {
                'text_length': len(text),
                'noise_level': 0.3,
                'recognition_confidence': 0.9
            }
            
            # è¤‡æ•°å›å®Ÿè¡Œã—ã¦å¹³å‡å‡¦ç†æ™‚é–“ã‚’è¨ˆæ¸¬
            times = []
            for _ in range(5):
                start = time.perf_counter()
                is_verified, confidence, details = verifier.verify_wake_word(text, context)
                end = time.perf_counter()
                times.append((end - start) * 1000)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            # æœŸå¾…æ™‚é–“ã¨ã®æ¯”è¼ƒ
            performance_mark = "ğŸš€" if avg_time <= expected_time else "âš ï¸" if avg_time <= expected_time * 1.5 else "ğŸŒ"
            
            if avg_time <= expected_time:
                fast_count += 1
            
            total_time += avg_time
            
            print(f"{performance_mark} {i:2d}. {description}")
            print(f"     å…¥åŠ›: '{text[:30]}{'...' if len(text) > 30 else ''}'")
            print(f"     çµæœ: {is_verified} (ä¿¡é ¼åº¦: {confidence:.3f})")
            print(f"     å‡¦ç†æ™‚é–“: å¹³å‡{avg_time:.1f}ms (ç¯„å›²: {min_time:.1f}-{max_time:.1f}ms)")
            print(f"     æœŸå¾…æ™‚é–“: {expected_time}ms â†’ {'âœ…é”æˆ' if avg_time <= expected_time else 'âŒè¶…é'}")
            print()
        
        # ç·åˆçµæœ
        avg_total_time = total_time / len(test_cases)
        performance_ratio = fast_count / len(test_cases) * 100
        
        print("=" * 70)
        print("ğŸ“ˆ ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ:")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_total_time:.2f}ms")
        print(f"   æœŸå¾…æ™‚é–“é”æˆç‡: {performance_ratio:.1f}% ({fast_count}/{len(test_cases)})")
        
        # çµ±è¨ˆæƒ…å ±
        stats = verifier.get_verification_statistics()
        print(f"   ç·æ¤œè¨¼å›æ•°: {stats['total_verifications']}")
        print(f"   æˆåŠŸç‡: {stats['accuracy_rate']:.1%}")
        print(f"   èª¤æ¤œçŸ¥é˜²æ­¢ç‡: {stats['false_positive_prevention_rate']:.1%}")
        
        if performance_ratio >= 80:
            print("ğŸ‰ å„ªç§€ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã™ï¼")
        elif performance_ratio >= 60:
            print("âœ… è‰¯å¥½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã™ã€‚")
        else:
            print("âš ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        
        return performance_ratio >= 60
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_algorithm_selection():
    """ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠã®æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
    print("-" * 50)
    
    try:
        from phonetic_similarity import PhoneticSimilarityCalculator
        
        calculator = PhoneticSimilarityCalculator()
        
        test_cases = [
            ("ãƒ«ã‚¯ã‚¹", "ã‚‹ãã™", "çŸ­æ–‡å‡¦ç†"),
            ("ãƒ«ã‚¯ã‚¹ ä»Šæ—¥ã®å¤©æ°—", "ã‚‹ãã™", "é•·æ–‡å‡¦ç†"),
            ("ã‚‰ãã™", "ã‚‹ãã™", "éŸ³éŸ»å¤‰åŒ–"),
        ]
        
        for text1, text2, description in test_cases:
            start = time.perf_counter()
            similarity = calculator.calculate_phonetic_similarity(text1, text2)
            end = time.perf_counter()
            
            processing_time = (end - start) * 1000
            
            # ä½¿ç”¨ã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¨å®š
            text_len = max(len(text1), len(text2))
            if text_len <= calculator.short_text_threshold:
                algorithm = "å˜ä¸€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç·¨é›†è·é›¢ï¼‰"
            else:
                algorithm = "ãƒãƒ«ãƒã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ " if calculator.enable_multi_algorithm else "å˜ä¸€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ "
            
            print(f"âœ… {description}")
            print(f"   å…¥åŠ›: '{text1}' vs '{text2}'")
            print(f"   é¡ä¼¼åº¦: {similarity:.3f}")
            print(f"   å‡¦ç†æ™‚é–“: {processing_time:.1f}ms")
            print(f"   ä½¿ç”¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {algorithm}")
            print()
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ éŸ³éŸ»çš„é¡ä¼¼åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  - æœ€é©åŒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    performance_ok = test_performance_optimization()
    algorithm_ok = test_algorithm_selection()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
    print(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if performance_ok else 'âŒ å¤±æ•—'}")
    print(f"ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if algorithm_ok else 'âŒ å¤±æ•—'}")
    
    if performance_ok and algorithm_ok:
        print("\nğŸ‰ ã™ã¹ã¦ã®æœ€é©åŒ–ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
        print("éŸ³éŸ»çš„é¡ä¼¼åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®å‡¦ç†é€Ÿåº¦ãŒå‘ä¸Šã—ã¾ã—ãŸã€‚")
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®æœ€é©åŒ–ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
        print("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
