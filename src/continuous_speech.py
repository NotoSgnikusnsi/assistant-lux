"""
å¸¸æ™‚éŸ³å£°ç›£è¦–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°èªè­˜ã§ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’å¸¸æ™‚ç›£è¦–
"""

import threading
import queue
import time
import numpy as np
import pyaudio
import speech_recognition as sr
from typing import Optional, Callable, Tuple
import webrtcvad
import collections


class ContinuousSpeechMonitor:
    """å¸¸æ™‚éŸ³å£°ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, language: str = "ja-JP", wake_words: list = None):
        """
        åˆæœŸåŒ–
        
        Args:
            language: èªè­˜è¨€èª
            wake_words: ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        self.language = language
        self.wake_words = wake_words or ["ãƒ«ã‚¯ã‚¹", "ã‚‹ãã™", "Lux", "lux"]
        
        # éŸ³å£°è¨­å®š
        self.sample_rate = 16000
        self.chunk_duration_ms = 30  # 30ms chunks
        self.chunk_size = int(self.sample_rate * self.chunk_duration_ms / 1000)
        self.format = pyaudio.paInt16
        self.channels = 1
        
        # PyAudioåˆæœŸåŒ–
        self.audio = pyaudio.PyAudio()
        self.stream = None
        
        # éŸ³å£°èªè­˜åˆæœŸåŒ–
        self.recognizer = sr.Recognizer()
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = False
        self.recognizer.pause_threshold = 0.8
        
        # VAD (Voice Activity Detection) åˆæœŸåŒ–
        self.vad = webrtcvad.Vad(2)  # æ„Ÿåº¦: 0(ä½) - 3(é«˜)
        self.volume_threshold = 500  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨éŸ³é‡é–¾å€¤
        
        # ãƒãƒƒãƒ•ã‚¡ç®¡ç†
        self.audio_buffer = collections.deque(maxlen=100)  # ç´„3ç§’åˆ†
        self.voice_buffer = []
        self.is_voice_active = False
        self.voice_start_time = None
        self.silence_duration = 0
        
        # åˆ¶å¾¡ãƒ•ãƒ©ã‚°
        self.is_running = False
        self.monitoring_thread = None
        self.processing_thread = None
        
        # ã‚­ãƒ¥ãƒ¼ã¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.audio_queue = queue.Queue()
        self.wake_word_callback = None
        self.command_callback = None
        
        print("å¸¸æ™‚éŸ³å£°ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def set_wake_word_callback(self, callback: Callable[[str, str], None]):
        """
        ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        
        Args:
            callback: (æ¤œçŸ¥ãƒ†ã‚­ã‚¹ãƒˆ, æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰) -> None
        """
        self.wake_word_callback = callback
    
    def set_command_callback(self, callback: Callable[[str], None]):
        """
        ã‚³ãƒãƒ³ãƒ‰æ¤œçŸ¥æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        
        Args:
            callback: (ã‚³ãƒãƒ³ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆ) -> None
        """
        self.command_callback = callback
    
    def start_monitoring(self):
        """éŸ³å£°ç›£è¦–é–‹å§‹"""
        if self.is_running:
            return
        
        print("å¸¸æ™‚éŸ³å£°ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™...")
        
        try:
            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
            self.stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                stream_callback=self._audio_callback
            )
            
            self.is_running = True
            
            # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
            self.monitoring_thread = threading.Thread(target=self._monitor_loop, daemon=True)
            self.processing_thread = threading.Thread(target=self._process_loop, daemon=True)
            
            self.monitoring_thread.start()
            self.processing_thread.start()
            
            print("âœ… å¸¸æ™‚éŸ³å£°ç›£è¦–é–‹å§‹")
            
        except Exception as e:
            print(f"éŸ³å£°ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            self.stop_monitoring()
    
    def stop_monitoring(self):
        """éŸ³å£°ç›£è¦–åœæ­¢"""
        if not self.is_running:
            return
        
        print("å¸¸æ™‚éŸ³å£°ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™...")
        
        self.is_running = False
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†å¾…æ©Ÿ
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=2)
        if self.processing_thread:
            self.processing_thread.join(timeout=2)
        
        print("âœ… å¸¸æ™‚éŸ³å£°ç›£è¦–åœæ­¢")
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """
        PyAudio ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ - éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å—ä¿¡
        """
        try:
            self.audio_queue.put(in_data)
        except:
            pass
        return (None, pyaudio.paContinue)
    
    def _monitor_loop(self):
        """éŸ³å£°ç›£è¦–ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        while self.is_running:
            try:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                audio_data = self.audio_queue.get(timeout=0.1)
                
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’NumPyé…åˆ—ã«å¤‰æ›
                audio_np = np.frombuffer(audio_data, dtype=np.int16)
                self.audio_buffer.append(audio_np)
                
                # VADã§éŸ³å£°æ´»å‹•æ¤œçŸ¥
                is_speech = self._detect_voice_activity(audio_data)
                
                if is_speech:
                    if not self.is_voice_active:
                        # éŸ³å£°é–‹å§‹
                        self.is_voice_active = True
                        self.voice_start_time = time.time()
                        self.voice_buffer = list(self.audio_buffer)  # éå»ã®ãƒãƒƒãƒ•ã‚¡ã‚‚å«ã‚ã‚‹
                        print("ğŸ¤ éŸ³å£°æ¤œçŸ¥")
                    else:
                        # éŸ³å£°ç¶™ç¶š
                        self.voice_buffer.append(audio_np)
                    
                    self.silence_duration = 0
                else:
                    if self.is_voice_active:
                        self.silence_duration += self.chunk_duration_ms
                        self.voice_buffer.append(audio_np)
                        
                        # éŸ³å£°çµ‚äº†åˆ¤å®šï¼ˆ500msä»¥ä¸Šã®ç„¡éŸ³ï¼‰
                        if self.silence_duration >= 500:
                            self._process_voice_segment()
                            self.is_voice_active = False
                            self.voice_buffer = []
                            self.silence_duration = 0
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"éŸ³å£°ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _process_loop(self):
        """éŸ³å£°å‡¦ç†ãƒ«ãƒ¼ãƒ—ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        # ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¯å°†æ¥çš„ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ç”¨
        while self.is_running:
            time.sleep(0.1)
    
    def _detect_voice_activity(self, audio_data: bytes) -> bool:
        """
        VADã‚’ä½¿ç”¨ã—ãŸéŸ³å£°æ´»å‹•æ¤œçŸ¥
        
        Args:
            audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            éŸ³å£°ãŒæ¤œçŸ¥ã•ã‚ŒãŸã‹ã©ã†ã‹
        """
        try:
            # VADã¯10ms, 20ms, 30msã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’ã‚µãƒãƒ¼ãƒˆ
            return self.vad.is_speech(audio_data, self.sample_rate)
        except:
            # VADã‚¨ãƒ©ãƒ¼æ™‚ã¯éŸ³é‡ã§åˆ¤å®š
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            volume = np.sqrt(np.mean(audio_np**2))
            return volume > self.volume_threshold
    
    def _process_voice_segment(self):
        """éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å‡¦ç†"""
        if not self.voice_buffer:
            return
        
        try:
            # éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’çµåˆ
            audio_segment = np.concatenate(self.voice_buffer)
            
            # éŸ³å£°èªè­˜å®Ÿè¡Œ
            text = self._recognize_audio_segment(audio_segment)
            
            if text:
                print(f"ğŸ¯ éŸ³å£°èªè­˜: '{text}'")
                
                # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥
                is_wake_word, extracted_command = self._check_wake_word(text)
                
                if is_wake_word:
                    print(f"ğŸš¨ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥: '{text}'")
                    if self.wake_word_callback:
                        self.wake_word_callback(text, extracted_command)
                else:
                    print(f"ğŸ“ é€šå¸¸éŸ³å£°: '{text}'")
        
        except Exception as e:
            print(f"éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _recognize_audio_segment(self, audio_data: np.ndarray) -> Optional[str]:
        """
        éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’èªè­˜
        
        Args:
            audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
            audio_data = audio_data.astype(np.float32) / 32768.0
            
            # speech_recognitionç”¨ã®AudioDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
            audio_bytes = (audio_data * 32768).astype(np.int16).tobytes()
            audio_sr = sr.AudioData(audio_bytes, self.sample_rate, 2)
            
            # Google Speech Recognitionå®Ÿè¡Œ
            text = self.recognizer.recognize_google(audio_sr, language=self.language)
            return text
            
        except sr.UnknownValueError:
            return None
        except sr.RequestError as e:
            print(f"éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return None
        except Exception as e:
            print(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _check_wake_word(self, text: str) -> Tuple[bool, str]:
        """
        ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        
        Args:
            text: èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            (ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥ãƒ•ãƒ©ã‚°, æŠ½å‡ºã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰)
        """
        if not text:
            return False, ""
        
        text_lower = text.lower()
        
        # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥
        for wake_word in self.wake_words:
            wake_word_lower = wake_word.lower()
            if wake_word_lower in text_lower:
                # ã‚³ãƒãƒ³ãƒ‰æŠ½å‡º
                wake_word_index = text_lower.find(wake_word_lower)
                command = text[wake_word_index + len(wake_word):].strip()
                command = command.lstrip('ã€ã€‚ï¼Œ,')
                return True, command
        
        # æ›–æ˜§ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        fuzzy_matches = {
            "ãƒ©ãƒƒã‚¯ã‚¹": "ãƒ«ã‚¯ã‚¹", "ã‚‰ã£ãã™": "ãƒ«ã‚¯ã‚¹",  
            "ãƒ«ãƒƒã‚¯ã‚¹": "ãƒ«ã‚¯ã‚¹", "ã‚‹ã£ãã™": "ãƒ«ã‚¯ã‚¹",
            "luck": "Lux", "lacks": "Lux"
        }
        
        for fuzzy_word, wake_word in fuzzy_matches.items():
            if fuzzy_word.lower() in text_lower:
                fuzzy_index = text_lower.find(fuzzy_word.lower())
                command = text[fuzzy_index + len(fuzzy_word):].strip()
                command = command.lstrip('ã€ã€‚ï¼Œ,')
                return True, command
        
        return False, ""
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.stop_monitoring()
        
        if hasattr(self, 'audio') and self.audio:
            self.audio.terminate()


def test_continuous_speech():
    """å¸¸æ™‚éŸ³å£°ç›£è¦–ã®ãƒ†ã‚¹ãƒˆ"""
    print("=== å¸¸æ™‚éŸ³å£°ç›£è¦–ãƒ†ã‚¹ãƒˆ ===")
    
    def on_wake_word(text, command):
        print(f"âœ… ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥: '{text}', ã‚³ãƒãƒ³ãƒ‰: '{command}'")
    
    monitor = ContinuousSpeechMonitor()
    monitor.set_wake_word_callback(on_wake_word)
    
    try:
        monitor.start_monitoring()
        print("ç›£è¦–ä¸­... Ctrl+Cã§çµ‚äº†")
        
        while True:
            time.sleep(1)
    
    except KeyboardInterrupt:
        print("\nç›£è¦–çµ‚äº†")
    finally:
        monitor.cleanup()


if __name__ == "__main__":
    test_continuous_speech()
