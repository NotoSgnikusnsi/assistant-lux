"""
éŸ³å£°å…¥åŠ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°å…¥åŠ›ã¨éŒ²éŸ³æ©Ÿèƒ½ã‚’æä¾›
"""

import sounddevice as sd
import soundfile as sf
import numpy as np
import queue
import threading
import time
from typing import Optional, Callable


class AudioInputHandler:
    """éŸ³å£°å…¥åŠ›ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 sample_rate: int = 16000,
                 channels: int = 1,
                 chunk_size: int = 1024,
                 recording_duration: int = 10):
        """
        åˆæœŸåŒ–
        
        Args:
            sample_rate: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
            channels: ãƒãƒ£ãƒ³ãƒãƒ«æ•°ï¼ˆ1=ãƒ¢ãƒãƒ©ãƒ«ï¼‰
            chunk_size: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
            recording_duration: éŒ²éŸ³æ™‚é–“ä¸Šé™ï¼ˆç§’ï¼‰
        """
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk_size = chunk_size
        self.recording_duration = recording_duration
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨
        self.audio_queue = queue.Queue()
        self.is_recording = False
        self.recorded_data = []
        
        print(f"éŸ³å£°å…¥åŠ›åˆæœŸåŒ–å®Œäº†: {sample_rate}Hz, {channels}ch")
        
    def get_available_devices(self):
        """åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã‚’å–å¾—"""
        devices = sd.query_devices()
        print("\n=== åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ ===")
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:  # å…¥åŠ›å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã®ã¿
                print(f"{i}: {device['name']} (å…¥åŠ›: {device['max_input_channels']}ch)")
        return devices
    
    def audio_callback(self, indata, frames, time, status):
        """éŸ³å£°å…¥åŠ›ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
        if status:
            print(f"éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {status}")
        
        if self.is_recording:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            self.audio_queue.put(indata.copy())
    
    def start_monitoring(self, volume_threshold: float = 0.01):
        """éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚’é–‹å§‹"""
        print("éŸ³å£°ç›£è¦–ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")
        print("ä½•ã‹è©±ã—ã¦ãã ã•ã„ï¼ˆCtrl+Cã§çµ‚äº†ï¼‰")
        
        try:
            with sd.InputStream(
                samplerate=self.sample_rate,
                channels=self.channels,
                callback=self.audio_callback,
                blocksize=self.chunk_size
            ):
                while True:
                    time.sleep(0.1)
                    # ç°¡å˜ãªéŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤º
                    if not self.audio_queue.empty():
                        data = self.audio_queue.get()
                        volume = np.sqrt(np.mean(data**2))
                        if volume > volume_threshold:
                            print(f"éŸ³å£°æ¤œçŸ¥: {volume:.4f}")
                            
        except KeyboardInterrupt:
            print("\néŸ³å£°ç›£è¦–ã‚’çµ‚äº†ã—ã¾ã™")
    
    def record_audio_with_vad(self, 
                             max_duration: int = 10,
                             silence_threshold: float = 0.005,
                             min_duration: float = 0.5,
                             post_silence_duration: float = 1.0) -> np.ndarray:
        """
        éŸ³å£°æ´»å‹•æ¤œå‡º(VAD)ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒãƒ¼ãƒˆéŒ²éŸ³
        
        Args:
            max_duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            silence_threshold: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤
            min_duration: æœ€å°éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            post_silence_duration: ç™ºè©±çµ‚äº†å¾Œã®å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿
        """
        print("ğŸ¤ éŸ³å£°æ¤œå‡ºã‚’é–‹å§‹...")
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
        self.recorded_data = []
        self.is_recording = True
        
        start_time = time.time()
        last_voice_time = start_time
        voice_detected = False
        silence_start_time = None
        
        # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
        with sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            callback=self.audio_callback,
            blocksize=self.chunk_size
        ):
            while self.is_recording:
                current_time = time.time()
                
                # æœ€å¤§éŒ²éŸ³æ™‚é–“ãƒã‚§ãƒƒã‚¯
                if current_time - start_time > max_duration:
                    print(f"â° æœ€å¤§éŒ²éŸ³æ™‚é–“({max_duration}ç§’)ã«åˆ°é”")
                    break
                
                try:
                    # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆçŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                    data = self.audio_queue.get(timeout=0.05)
                    self.recorded_data.append(data)
                    
                    # éŸ³å£°ãƒ¬ãƒ™ãƒ«è¨ˆç®—
                    volume = np.sqrt(np.mean(data**2))
                    
                    # éŸ³å£°æ¤œå‡º
                    if volume > silence_threshold:
                        if not voice_detected:
                            print("ğŸ”Š éŸ³å£°æ¤œå‡º")
                            voice_detected = True
                        last_voice_time = current_time
                        silence_start_time = None
                    else:
                        # ç„¡éŸ³æ¤œå‡º
                        if voice_detected and silence_start_time is None:
                            silence_start_time = current_time
                        
                        # ç™ºè©±çµ‚äº†åˆ¤å®š
                        if (voice_detected and 
                            silence_start_time and 
                            current_time - silence_start_time > post_silence_duration and
                            current_time - start_time > min_duration):
                            print("ğŸ”‡ ç™ºè©±çµ‚äº†ã‚’æ¤œå‡º")
                            break
                            
                except queue.Empty:
                    continue
        
        self.is_recording = False
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        if self.recorded_data:
            audio_data = np.concatenate(self.recorded_data, axis=0)
            duration = len(audio_data) / self.sample_rate
            print(f"âœ… éŒ²éŸ³å®Œäº†: {duration:.2f}ç§’")
            return audio_data
        else:
            print("âš ï¸ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return np.array([])
    
    def record_audio(self, duration: Optional[int] = None) -> np.ndarray:
        """
        éŸ³å£°ã‚’éŒ²éŸ³ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰
        
        Args:
            duration: éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰ã€‚Noneã®å ´åˆã¯VADã‚’ä½¿ç”¨
            
        Returns:
            éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿
        """
        if duration is None:
            # VADã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒãƒ¼ãƒˆéŒ²éŸ³
            return self.record_audio_with_vad()
        
        # å¾“æ¥ã®å›ºå®šæ™‚é–“éŒ²éŸ³
        print(f"éŒ²éŸ³é–‹å§‹: {duration}ç§’é–“éŒ²éŸ³ã—ã¾ã™...")
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
        self.recorded_data = []
        self.is_recording = True
        
        # éŒ²éŸ³ã‚¿ã‚¤ãƒãƒ¼
        def stop_recording():
            time.sleep(duration)
            self.is_recording = False
            print("éŒ²éŸ³çµ‚äº†")
        
        timer_thread = threading.Thread(target=stop_recording)
        timer_thread.start()
        
        # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
        with sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            callback=self.audio_callback,
            blocksize=self.chunk_size
        ):
            # éŒ²éŸ³ä¸­ã®å‡¦ç†
            while self.is_recording:
                try:
                    # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    data = self.audio_queue.get(timeout=0.1)
                    self.recorded_data.append(data)
                except queue.Empty:
                    continue
        
        timer_thread.join()
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        if self.recorded_data:
            audio_data = np.concatenate(self.recorded_data, axis=0)
            print(f"éŒ²éŸ³å®Œäº†: {len(audio_data)/self.sample_rate:.2f}ç§’")
            return audio_data
        else:
            print("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return np.array([])
    
    def save_audio(self, audio_data: np.ndarray, filename: str):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            sf.write(filename, audio_data, self.sample_rate)
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {filename}")
        except Exception as e:
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def detect_silence(self, audio_data: np.ndarray, 
                      silence_threshold: float = 0.01,
                      silence_duration: float = 2.0) -> bool:
        """
        ç„¡éŸ³ã‚’æ¤œçŸ¥
        
        Args:
            audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
            silence_threshold: ç„¡éŸ³ã®é–¾å€¤
            silence_duration: ç„¡éŸ³ã¨åˆ¤å®šã™ã‚‹ç¶™ç¶šæ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            ç„¡éŸ³ãŒæ¤œçŸ¥ã•ã‚ŒãŸã‹ã©ã†ã‹
        """
        # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®è¨ˆç®—
        frame_length = int(self.sample_rate * 0.1)  # 0.1ç§’ãƒ•ãƒ¬ãƒ¼ãƒ 
        silence_frames = int(silence_duration / 0.1)
        
        consecutive_silence = 0
        
        for i in range(0, len(audio_data), frame_length):
            frame = audio_data[i:i+frame_length]
            if len(frame) > 0:
                volume = np.sqrt(np.mean(frame**2))
                if volume < silence_threshold:
                    consecutive_silence += 1
                    if consecutive_silence >= silence_frames:
                        return True
                else:
                    consecutive_silence = 0
        
        return False
    
    def stream_audio_realtime(self, 
                             callback: Callable[[np.ndarray], bool],
                             chunk_duration: float = 0.1) -> None:
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
        
        Args:
            callback: éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
                     æˆ»ã‚Šå€¤ãŒFalseã®å ´åˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’åœæ­¢
            chunk_duration: ãƒãƒ£ãƒ³ã‚¯ã®æ™‚é–“é–“éš”ï¼ˆç§’ï¼‰
        """
        print("ğŸ”„ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹")
        
        chunk_samples = int(self.sample_rate * chunk_duration)
        buffer = np.array([])
        
        self.is_recording = True
        
        with sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            callback=self.audio_callback,
            blocksize=self.chunk_size
        ):
            while self.is_recording:
                try:
                    # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    data = self.audio_queue.get(timeout=0.05)
                    buffer = np.concatenate([buffer, data.flatten()])
                    
                    # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰å‡¦ç†
                    while len(buffer) >= chunk_samples:
                        chunk = buffer[:chunk_samples]
                        buffer = buffer[chunk_samples:]
                        
                        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
                        continue_streaming = callback(chunk)
                        if not continue_streaming:
                            self.is_recording = False
                            break
                            
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
                    break
        
        print("ğŸ›‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµ‚äº†")
    
    def capture_wake_word_optimized(self, 
                                   wake_word_detector: Callable[[np.ndarray], tuple[bool, str]],
                                   max_capture_time: float = 5.0) -> tuple[bool, str, np.ndarray]:
        """
        ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã«æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£
        
        Args:
            wake_word_detector: ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºé–¢æ•°
            max_capture_time: æœ€å¤§ã‚­ãƒ£ãƒ—ãƒãƒ£æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            (ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º, èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ, éŸ³å£°ãƒ‡ãƒ¼ã‚¿)
        """
        detected_text = ""
        captured_audio = np.array([])
        wake_word_found = False
        
        start_time = time.time()
        
        def process_chunk(chunk: np.ndarray) -> bool:
            nonlocal detected_text, captured_audio, wake_word_found
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©
            captured_audio = np.concatenate([captured_audio, chunk])
            
            # æœ€å¤§æ™‚é–“ãƒã‚§ãƒƒã‚¯
            if time.time() - start_time > max_capture_time:
                return False
            
            # ä¸€å®šé‡ã®ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚ŒãŸã‚‰ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’è©¦è¡Œ
            if len(captured_audio) > self.sample_rate * 1.0:  # 1ç§’ä»¥ä¸Š
                try:
                    found, text = wake_word_detector(captured_audio)
                    if found:
                        detected_text = text
                        wake_word_found = True
                        return False  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢
                except Exception as e:
                    print(f"ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            
            return True  # ç¶™ç¶š
        
        self.stream_audio_realtime(process_chunk, chunk_duration=0.1)
        
        return wake_word_found, detected_text, captured_audio


def test_audio_input():
    """éŸ³å£°å…¥åŠ›ã®ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("=== éŸ³å£°å…¥åŠ›ãƒ†ã‚¹ãƒˆ ===")
    
    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–
    audio_handler = AudioInputHandler()
    
    # åˆ©ç”¨å¯èƒ½ãƒ‡ãƒã‚¤ã‚¹è¡¨ç¤º
    audio_handler.get_available_devices()
    
    try:
        print("\n1. éŸ³å£°ç›£è¦–ãƒ†ã‚¹ãƒˆï¼ˆ10ç§’é–“ï¼‰")
        # çŸ­æ™‚é–“ã®ç›£è¦–ãƒ†ã‚¹ãƒˆ
        audio_handler.start_monitoring()
        
    except KeyboardInterrupt:
        print("\nãƒ†ã‚¹ãƒˆã‚’çµ‚äº†ã—ã¾ã™")


if __name__ == "__main__":
    test_audio_input()
